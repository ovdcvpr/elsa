{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Predict\n",
    "\n",
    "This notebook demonstrates how to leverage the model to make object detection predictions.\n"
   ],
   "id": "c9930d9e01461c68"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In the previous segment we showed how to view the ground truth annotation boxes. Now we will use an OVD model to make predictions\n",
    "on the same images so that we may perform some evaluations next. Let's initialize Elsa oncemore. Unless you have set the configuration, you must pass the image directories. "
   ],
   "id": "9753a59c98c1f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T01:07:00.110592Z",
     "start_time": "2024-11-22T01:06:57.977731Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from elsa import Elsa\n",
    "google = \"/home/redacted/Downloads/yolo/images/\"\n",
    "bing = '/home/redacted/Downloads/images/'\n",
    "files = google, bing\n",
    "elsa = Elsa.from_unified(files=files, quiet=True)\n",
    "elsa"
   ],
   "id": "b722712cfb8c46fd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Empty Elsa\n",
       "Columns: []\n",
       "Index: [BSV_0, BSV_1, BSV_10, BSV_100, BSV_101, BSV_102, BSV_104, BSV_105, BSV_106, BSV_107, BSV_108, BSV_109, BSV_11, BSV_110, BSV_111, BSV_112, BSV_113, BSV_115, BSV_116, BSV_117, BSV_118, BSV_119, BSV_12, BSV_121, BSV_122, BSV_123, BSV_124, BSV_125, BSV_127, BSV_128, BSV_129, BSV_13, BSV_131, BSV_132, BSV_133, BSV_134, BSV_136, BSV_137, BSV_139, BSV_14, BSV_140, BSV_141, BSV_142, BSV_143, BSV_145, BSV_146, BSV_147, BSV_149, BSV_150, BSV_151, BSV_152, BSV_153, BSV_155, BSV_156, BSV_157, BSV_158, BSV_159, BSV_16, BSV_160, BSV_161, BSV_162, BSV_164, BSV_166, BSV_167, BSV_168, BSV_169, BSV_17, BSV_170, BSV_171, BSV_172, BSV_173, BSV_174, BSV_175, BSV_176, BSV_177, BSV_178, BSV_18, BSV_180, BSV_181, BSV_183, BSV_184, BSV_185, BSV_186, BSV_187, BSV_188, BSV_189, BSV_19, BSV_190, BSV_191, BSV_192, BSV_193, BSV_194, BSV_195, BSV_196, BSV_197, BSV_198, BSV_199, BSV_2, BSV_20, BSV_200, ...]\n",
       "\n",
       "[934 rows x 0 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ifile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BSV_0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSV_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSV_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSV_100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BSV_101</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSV_95</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSV_96</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSV_97</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSV_98</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GSV_99</th>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>934 rows × 0 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:31:09.683395Z",
     "start_time": "2024-11-22T00:31:09.681103Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# you can also modify the code in your clone to add entries where the key is your username and the value is the path in the elsa.local.config files\n",
    "from elsa.local import config\n",
    "config['files']['bing'] \n",
    "config['files']['google']"
   ],
   "id": "1c8a4229c853e6a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'redacted': '/home/redacted/Downloads/yolo/images/',\n",
       " 'redacted': '/scratch/datasets/redacted/label_1k/old/google/images'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "By default, we are predicting with the [Open-GroundingDINO model](https://github.com/longzw1997/Open-GroundingDino).  \n",
    "No parameters are required: you can start inference just by calling `elsa.predict()`! However, here are some \n",
    "parameters that you can set:\n",
    "\n",
    "- outdir: Directory where the predictions will be saved. By default saves to /predict under the current working directory.\n",
    "- batch_size: Batch size to use for inference: default is 1, which will be slow. Increase it based on your system's capacity.\n",
    "- synonyms: Number of synonyms to use for each prompt\n",
    "- config: Model configuration file. We use `config/cfg_odvg.py` by default. [See Open-GroundingDino.](https://github.com/longzw1997/Open-GroundingDino?tab=readme-ov-file#config)\n",
    "- checkpoint: Model weights. We use `GroundingDINO-T (fine-tune)` by default. [See Open-GroundingDino.](https://github.com/longzw1997/Open-GroundingDino?tab=readme-ov-file#results-and-models)\n",
    "- force: If True, will overwrite the existing predictions.\n",
    "- prompts: \n",
    "    - list/Series/ndarray: boolean mask, aligned with `elsa.prompts`, selecting which prompts to use.\n",
    "    - int: Number of prompts to use: 5 means the first 5 prompts will be used.\n",
    "- files\n",
    "    - list/Series/ndarray: boolean mask, aligned with `elsa.files`, selecting which files to predict.  \n",
    "    - int: Number of files to predict: 5 means the first 5 files will be used.\n",
    "    - please note this will make each prediction file a subset of a whole prediction. You would then need to use force=True to overwrite it for a full prediction.\n"
   ],
   "id": "a9dbbfd6d64c4eb4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Quick Test Run\n",
    "Before we start predicting, let's do a quick test run with the first 2 prompts and 2 files. Force will specify that this prediction runs regardless of the contents in your output directory."
   ],
   "id": "1a99a4daf31f3e2d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:32:39.002515Z",
     "start_time": "2024-11-22T00:32:34.999745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "batch_size = 4\n",
    "prompts = 2 \n",
    "elsa.predict(batch_size=batch_size, prompts=prompts, files=2, force=True)"
   ],
   "id": "f85facc6620aff66",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-21 18:32:35.088707: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-21 18:32:35.097329: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-21 18:32:35.099824: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]INFO     truth.unique.stacked.consumed.prompts.ilabels_string\n",
      "INFO         classes.ilabels_string\n",
      "/home/redacted/PycharmProjects/sirius/.venv311/lib/python3.11/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n",
      "load tokenizer done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/redacted/PycharmProjects/sirius/src/elsa/predict/gdino/model.py:88: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint, map_location=\"cpu\")\n",
      "/home/redacted/PycharmProjects/sirius/.venv311/lib/python3.11/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/redacted/PycharmProjects/sirius/.venv311/lib/python3.11/site-packages/open_groundingdino/models/GroundingDINO/transformer.py:870: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "INFO     labels.char2label\n",
      "INFO     cat2char\n",
      " 50%|█████     | 1/2 [00:02<00:02,  2.48s/it]/home/redacted/PycharmProjects/sirius/.venv311/lib/python3.11/site-packages/torch/utils/checkpoint.py:92: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n",
      "/home/redacted/PycharmProjects/sirius/.venv311/lib/python3.11/site-packages/open_groundingdino/models/GroundingDINO/transformer.py:870: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=False):\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.36s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "predict.gdino.batched\n",
       "                                                         outpath  iprompt\n",
       "natural                                                                  \n",
       "a person       /home/redacted/PycharmProjects/sirius/notebook...      120\n",
       "an individual  /home/redacted/PycharmProjects/sirius/notebook...      121"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outpath</th>\n",
       "      <th>iprompt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>natural</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a person</th>\n",
       "      <td>/home/redacted/PycharmProjects/sirius/notebook...</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>an individual</th>\n",
       "      <td>/home/redacted/PycharmProjects/sirius/notebook...</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Full Run\n",
    "By default, the output was in the 'predict' folder under the current working directory. We checked the folder and everything looks good. \n",
    "Now we can run inference on the full dataset. This will take very long, however, especially with a large batch size, so the rest of the notebook \n",
    "discusses how you may limit the number of prompts for which inference is run. If compute is not an issue, you may ignore the rest of the notebook.  "
   ],
   "id": "31428e6aca9532df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "elsa.predict(outdir='~Downloads/predictions', batch_size=8)\n",
   "id": "63af68d7e5251cde"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Limiting Synonymous Prompts\n",
    "Each class has many synonymous prompts available to see in `elsa.prompts`. By default, all synonymous prompts are used for a class. However, this may be overkill \n",
    "for the average user and result in a batch that takes days for the user to run on a personal computer. You may use the `synonyms` parameter to limit the number \n",
    "of synonymous prompts used for each class. If you want to run inference on a personal computre and do some quick analysis not for publishing, you may want to use \n",
    "the synonyms parameter to limit the number of synonymous prompts per class to less than 5. This parameter prioritizes the most diverse prompts. For example, a class\n",
    "might have the following prompts:\n",
    "- a person walking\n",
    "- a person strolling\n",
    "- an individual walking\n",
    "- an individual strolling\n",
    "\n",
    "There may be much more prompts available by default than the user\n",
    "requires, so there is a need to limit the amount of synonymous prompts.\n",
    "However, it is not sufficient to simply take the first N prompts.\n",
    "For example, selecting the first two prompts would result in:\n",
    "- a person walking\n",
    "- a person strolling\n",
    "\n",
    "These predictions are not sufficiently varied. The `synonyms` parameter ensures the most varied synonymous prompts are used. \n",
    "In this case, the first two would be:\n",
    "- a person walking\n",
    "- an individual strolling\n"
   ],
   "id": "39b6b3f822912dcf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "elsa.predict(outdir='~Downloads/predictions', batch_size=8, synonyms=4)",
   "id": "c6577fbca3d96b5a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Run with Specific Prompts\n",
    "\n",
    "In the previous chapter, 02-combos.ipynb, we went over how to visualize specific ground truth annotation boxes. \n",
    "Similiarly we can specify which prompts to run inference on, so that you don't have to run the full inference, which likely would take days. If you do not wish to\n",
    "run inference on the full set of prompts, there are some features available to specify which prompts for which inference is run. These mostly overlap with the `Combos` class because \n",
    "both are representing a class. \n",
    "\n",
    "The following columns are of interest:\n",
    "- natural: \"natural\" language prompt: the realistic and \"human\" prompt that is fed to the model\n",
    "- ilabels: ordered tuple of the label IDs representing a given prompt. For example, if the labels metadata contains the mapping {'person':1, 'walking':5}, a bounding box representing 'person walking' has the ilabels (0, 5). These are our \"classes\" in this open set classification problem.\n",
    "- level: level of the prompt, or the characters, e.g. cs, csa, csao\n",
    "\n",
    "\n",
    "The following methods are of interest:\n",
    "- includes: True where prompt has a label or category\n",
    "- excludes: False where prompt has a label or category\n",
    "- contains_substring: True where prompt label contains a substring\n"
   ],
   "id": "c9a7cb029aa632f3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:39:47.406422Z",
     "start_time": "2024-11-22T00:39:47.401895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompts = elsa.prompts\n",
    "prompts['natural level'.split()]"
   ],
   "id": "da144bd336aeb82b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "truth.unique.stacked.consumed.prompts\n",
       "                                             natural level\n",
       "iprompt                                                   \n",
       "120                                         a person     c\n",
       "121                                    an individual     c\n",
       "122                                          a human     c\n",
       "81            a person sitting on a chair or a bench    cs\n",
       "82       an individual sitting on a chair or a bench    cs\n",
       "...                                              ...   ...\n",
       "1021                  two people riding a wheelchair    cs\n",
       "1022                          a pair on a wheelchair    cs\n",
       "1023                      a pair riding a wheelchair    cs\n",
       "1024                      two humans on a wheelchair    cs\n",
       "1025                  two humans riding a wheelchair    cs\n",
       "\n",
       "[830 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>natural</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>a person</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>an individual</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>a human</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>a person sitting on a chair or a bench</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>an individual sitting on a chair or a bench</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021</th>\n",
       "      <td>two people riding a wheelchair</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1022</th>\n",
       "      <td>a pair on a wheelchair</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>a pair riding a wheelchair</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>two humans on a wheelchair</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>two humans riding a wheelchair</td>\n",
       "      <td>cs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>830 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Run Inference where a specific label is included\n",
    "Here we create a boolean mask, selecting all the prompts that contain the 'person' label."
   ],
   "id": "a57c787dc804e96d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:39:49.126010Z",
     "start_time": "2024-11-22T00:39:49.120024Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompts = elsa.prompts.includes('person').values\n",
    "elsa.prompts.natural.loc[prompts]\n",
    "# elsa.predict(outdir=..., prompts=prompts)"
   ],
   "id": "96e9b04f3f75f68e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "truth.unique.stacked.consumed.prompts.natural\n",
       "iprompt\n",
       "120                                       a person\n",
       "121                                  an individual\n",
       "122                                        a human\n",
       "81          a person sitting on a chair or a bench\n",
       "82     an individual sitting on a chair or a bench\n",
       "                          ...                     \n",
       "823                   a person riding a wheelchair\n",
       "824                  an individual on a wheelchair\n",
       "825              an individual riding a wheelchair\n",
       "826                        a human on a wheelchair\n",
       "827                    a human riding a wheelchair\n",
       "Name: natural, Length: 291, dtype: category\n",
       "Categories (830, object): ['a child pushing a stroller and strolling to c..., 'a child pushing a stroller and walking to cro..., 'a child standing', 'a child strolling', ..., 'two people walking and riding a wheelchair', 'two people walking to cross a crosswalk', 'two people walking to cross a crosswalk and o..., 'two people walking to cross a crosswalk and r...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Run inference for only CSAO-level prompts\n",
    "We can select \n",
    "For a class or prompt to be CSAO-level it must have one of each of the following categories:\n",
    "- condition\n",
    "- state\n",
    "- activity\n",
    "- others\n",
    "An example would be \"A person walking to cross a crosswalk with a pet.\" \n",
    "- person: condition\n",
    "- walking: state\n",
    "- crossing crosswalk: activity\n",
    "- pet: other"
   ],
   "id": "be0d1317a228e327"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:39:52.228777Z",
     "start_time": "2024-11-22T00:39:52.224918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompts = elsa.prompts.level == 'csao'\n",
    "elsa.prompts.natural.loc[prompts]\n",
    "# elsa.predict(outdir=..., prompts=prompts)"
   ],
   "id": "604ebd97d0e24f52",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "truth.unique.stacked.consumed.prompts.natural\n",
       "iprompt\n",
       "996       a person with a pet walking with a mobility aid\n",
       "997       a person with a dog walking with a mobility aid\n",
       "998     a person with a pet strolling with a mobility aid\n",
       "999     a person with a dog strolling with a mobility aid\n",
       "1000    an individual with a pet walking with a mobili...\n",
       "                              ...                        \n",
       "973     a pair including a child strolling to cross a ...\n",
       "974     two humans including a kid walking to cross a ...\n",
       "975     two humans including a child walking to cross ...\n",
       "976     two humans including a kid strolling to cross ...\n",
       "977     two humans including a child strolling to cros...\n",
       "Name: natural, Length: 178, dtype: category\n",
       "Categories (830, object): ['a child pushing a stroller and strolling to c..., 'a child pushing a stroller and walking to cro..., 'a child standing', 'a child strolling', ..., 'two people walking and riding a wheelchair', 'two people walking to cross a crosswalk', 'two people walking to cross a crosswalk and o..., 'two people walking to cross a crosswalk and r...]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "#### Run Inference where there are two activities\n",
    "Perhaps we want to select the prompts that don't include or exclude any particular labels, but rather select the prompts which have two activities.\n",
    "For this we need to interact with the individual labels of the prompts, rather than the aggregate. We can view the individual\n",
    "labels of the prompts in \"stacked\" form by accessing `elsa.prompts.stacked`.\n",
    "\n",
    "## Stacked\n",
    "\n",
    "The following columns are of interest:\n",
    "- ilabels: ordered tuple of the label IDs representing a given prompt. For example, if the labels metadata contains the mapping {'person':1, 'walking':5}, a bounding box representing 'person walking' has the ilabels (0, 5). These are our \"classes\" in this open set classification problem.\n",
    "- label: name of the label that comprises the prompt\n",
    "- natural: \"natural\" version of the label. For example, \"person\" becomes \"a person\". These are concatenated to create the natural prompt.\n",
    "\n",
    "The following methods are of interest:\n",
    "- includes: True where a stacked synonym is equivalent to a label, or belongs to a category\n",
    "- excludes: False where a stacked synonym is equivalent to a label, or belongs to a category\n",
    "- contains_substring: True where stacked synonym's natural label contains a substring\n",
    "- get_nunique_labels: Pass a boolean mask aligned with the stacked labels from the prompts, and this will return the number of unique labels for each prompt.\n",
    "\n"
   ],
   "id": "a2adb81e2c1ae3c6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T00:39:57.750634Z",
     "start_time": "2024-11-22T00:39:57.742814Z"
    }
   },
   "cell_type": "code",
   "source": "elsa.prompts.stacked",
   "id": "95fc37d60d30a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "truth.unique.stacked.consumed\n",
       "         ilabels                      label  isyn   iorder  ilabel     isyns  \\\n",
       "iprompt                                                                        \n",
       "120         (0,)                     person     0  subject       0      (0,)   \n",
       "121         (0,)                 individual     1  subject       0      (1,)   \n",
       "122         (0,)                      human     4  subject       0      (4,)   \n",
       "81        (0, 3)                     person     0  subject       0   (0, 75)   \n",
       "81        (0, 3)  sitting on chair or bench    75     verb       3   (0, 75)   \n",
       "...          ...                        ...   ...      ...     ...       ...   \n",
       "1023     (2, 34)          riding wheelchair    43     verb      34  (22, 43)   \n",
       "1024     (2, 34)                 two humans    24  subject       2  (24, 40)   \n",
       "1024     (2, 34)              on wheelchair    40     verb      34  (24, 40)   \n",
       "1025     (2, 34)                 two humans    24  subject       2  (24, 43)   \n",
       "1025     (2, 34)          riding wheelchair    43     verb      34  (24, 43)   \n",
       "\n",
       "                               natural        cat cat_char  \\\n",
       "iprompt                                                      \n",
       "120                           a person  condition        c   \n",
       "121                      an individual  condition        c   \n",
       "122                            a human  condition        c   \n",
       "81                            a person  condition        c   \n",
       "81       sitting on a chair or a bench      state        s   \n",
       "...                                ...        ...      ...   \n",
       "1023               riding a wheelchair      state        s   \n",
       "1024                        two humans  condition        c   \n",
       "1024                   on a wheelchair      state        s   \n",
       "1025                        two humans  condition        c   \n",
       "1025               riding a wheelchair      state        s   \n",
       "\n",
       "                              catchars                         prompt  \\\n",
       "iprompt                                                                 \n",
       "120                           c cccccc                       a person   \n",
       "121                         cccccccccc                  an individual   \n",
       "122                              ccccc                        a human   \n",
       "81                              cccccc                       a person   \n",
       "81       sssssss      sssss      sssss  sitting on a chair or a bench   \n",
       "...                                ...                            ...   \n",
       "1023               ssssss   ssssssssss            riding a wheelchair   \n",
       "1024                        ccc cccccc                     two humans   \n",
       "1024                        ssssssssss                on a wheelchair   \n",
       "1025                        ccc cccccc                     two humans   \n",
       "1025               ssssss   ssssssssss            riding a wheelchair   \n",
       "\n",
       "        labelchar                     labelchars  \n",
       "iprompt                                           \n",
       "120             A                       A AAAAAA  \n",
       "121             A                     AAAAAAAAAA  \n",
       "122             A                          AAAAA  \n",
       "81              A                         AAAAAA  \n",
       "81              D  DDDDDDD      DDDDD      DDDDD  \n",
       "...           ...                            ...  \n",
       "1023            c            cccccc   cccccccccc  \n",
       "1024            C                     CCC CCCCCC  \n",
       "1024            c                     cccccccccc  \n",
       "1025            C                     CCC CCCCCC  \n",
       "1025            c            cccccc   cccccccccc  \n",
       "\n",
       "[2937 rows x 13 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ilabels</th>\n",
       "      <th>label</th>\n",
       "      <th>isyn</th>\n",
       "      <th>iorder</th>\n",
       "      <th>ilabel</th>\n",
       "      <th>isyns</th>\n",
       "      <th>natural</th>\n",
       "      <th>cat</th>\n",
       "      <th>cat_char</th>\n",
       "      <th>catchars</th>\n",
       "      <th>prompt</th>\n",
       "      <th>labelchar</th>\n",
       "      <th>labelchars</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>iprompt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>(0,)</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "      <td>subject</td>\n",
       "      <td>0</td>\n",
       "      <td>(0,)</td>\n",
       "      <td>a person</td>\n",
       "      <td>condition</td>\n",
       "      <td>c</td>\n",
       "      <td>c cccccc</td>\n",
       "      <td>a person</td>\n",
       "      <td>A</td>\n",
       "      <td>A AAAAAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>(0,)</td>\n",
       "      <td>individual</td>\n",
       "      <td>1</td>\n",
       "      <td>subject</td>\n",
       "      <td>0</td>\n",
       "      <td>(1,)</td>\n",
       "      <td>an individual</td>\n",
       "      <td>condition</td>\n",
       "      <td>c</td>\n",
       "      <td>cccccccccc</td>\n",
       "      <td>an individual</td>\n",
       "      <td>A</td>\n",
       "      <td>AAAAAAAAAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>(0,)</td>\n",
       "      <td>human</td>\n",
       "      <td>4</td>\n",
       "      <td>subject</td>\n",
       "      <td>0</td>\n",
       "      <td>(4,)</td>\n",
       "      <td>a human</td>\n",
       "      <td>condition</td>\n",
       "      <td>c</td>\n",
       "      <td>ccccc</td>\n",
       "      <td>a human</td>\n",
       "      <td>A</td>\n",
       "      <td>AAAAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>person</td>\n",
       "      <td>0</td>\n",
       "      <td>subject</td>\n",
       "      <td>0</td>\n",
       "      <td>(0, 75)</td>\n",
       "      <td>a person</td>\n",
       "      <td>condition</td>\n",
       "      <td>c</td>\n",
       "      <td>cccccc</td>\n",
       "      <td>a person</td>\n",
       "      <td>A</td>\n",
       "      <td>AAAAAA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>(0, 3)</td>\n",
       "      <td>sitting on chair or bench</td>\n",
       "      <td>75</td>\n",
       "      <td>verb</td>\n",
       "      <td>3</td>\n",
       "      <td>(0, 75)</td>\n",
       "      <td>sitting on a chair or a bench</td>\n",
       "      <td>state</td>\n",
       "      <td>s</td>\n",
       "      <td>sssssss      sssss      sssss</td>\n",
       "      <td>sitting on a chair or a bench</td>\n",
       "      <td>D</td>\n",
       "      <td>DDDDDDD      DDDDD      DDDDD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>(2, 34)</td>\n",
       "      <td>riding wheelchair</td>\n",
       "      <td>43</td>\n",
       "      <td>verb</td>\n",
       "      <td>34</td>\n",
       "      <td>(22, 43)</td>\n",
       "      <td>riding a wheelchair</td>\n",
       "      <td>state</td>\n",
       "      <td>s</td>\n",
       "      <td>ssssss   ssssssssss</td>\n",
       "      <td>riding a wheelchair</td>\n",
       "      <td>c</td>\n",
       "      <td>cccccc   cccccccccc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>(2, 34)</td>\n",
       "      <td>two humans</td>\n",
       "      <td>24</td>\n",
       "      <td>subject</td>\n",
       "      <td>2</td>\n",
       "      <td>(24, 40)</td>\n",
       "      <td>two humans</td>\n",
       "      <td>condition</td>\n",
       "      <td>c</td>\n",
       "      <td>ccc cccccc</td>\n",
       "      <td>two humans</td>\n",
       "      <td>C</td>\n",
       "      <td>CCC CCCCCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>(2, 34)</td>\n",
       "      <td>on wheelchair</td>\n",
       "      <td>40</td>\n",
       "      <td>verb</td>\n",
       "      <td>34</td>\n",
       "      <td>(24, 40)</td>\n",
       "      <td>on a wheelchair</td>\n",
       "      <td>state</td>\n",
       "      <td>s</td>\n",
       "      <td>ssssssssss</td>\n",
       "      <td>on a wheelchair</td>\n",
       "      <td>c</td>\n",
       "      <td>cccccccccc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>(2, 34)</td>\n",
       "      <td>two humans</td>\n",
       "      <td>24</td>\n",
       "      <td>subject</td>\n",
       "      <td>2</td>\n",
       "      <td>(24, 43)</td>\n",
       "      <td>two humans</td>\n",
       "      <td>condition</td>\n",
       "      <td>c</td>\n",
       "      <td>ccc cccccc</td>\n",
       "      <td>two humans</td>\n",
       "      <td>C</td>\n",
       "      <td>CCC CCCCCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>(2, 34)</td>\n",
       "      <td>riding wheelchair</td>\n",
       "      <td>43</td>\n",
       "      <td>verb</td>\n",
       "      <td>34</td>\n",
       "      <td>(24, 43)</td>\n",
       "      <td>riding a wheelchair</td>\n",
       "      <td>state</td>\n",
       "      <td>s</td>\n",
       "      <td>ssssss   ssssssssss</td>\n",
       "      <td>riding a wheelchair</td>\n",
       "      <td>c</td>\n",
       "      <td>cccccc   cccccccccc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2937 rows × 13 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-22T01:07:47.887905Z",
     "start_time": "2024-11-22T01:07:47.881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Generate a boolean mask of which stacked prompt labels include the 'activity' label\n",
    "activity = elsa.prompts.stacked.includes(cat='activity').values\n",
    "# Select the prompts where there are two activities for each \n",
    "activities = elsa.prompts.stacked.get_nunique_labels(activity) == 2\n",
    "elsa.prompts.loc[activities, 'natural']\n",
    "# elsa.predict(outdir=..., prompts=activities)"
   ],
   "id": "ae6ba7eb27322e8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "iprompt\n",
       "813    an individual talking and standing to cross a ...\n",
       "815    an individual chatting and standing to cross a...\n",
       "816    a person talking and standing to cross a cross...\n",
       "818    a person chatting and standing to cross a cros...\n",
       "819    a human talking and standing to cross a crosswalk\n",
       "                             ...                        \n",
       "230    two people chatting and walking to cross a cro...\n",
       "231    two humans talking and strolling to cross a cr...\n",
       "232    two humans talking and walking to cross a cros...\n",
       "235    two humans chatting and strolling to cross a c...\n",
       "236    two humans chatting and walking to cross a cro...\n",
       "Name: natural, Length: 121, dtype: category\n",
       "Categories (830, object): ['a child pushing a stroller and strolling to c..., 'a child pushing a stroller and walking to cro..., 'a child standing', 'a child strolling', ..., 'two people walking and riding a wheelchair', 'two people walking to cross a crosswalk', 'two people walking to cross a crosswalk and o..., 'two people walking to cross a crosswalk and r...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
